# GPT Researcher æ—¥å¿—ä¸å›è°ƒæ–‡æ¡£

## 1. æ—¥å¿—ç³»ç»Ÿå®ç°

### 1.1 æ—¥å¿—æ¡†æ¶

GPT Researcher ä½¿ç”¨ Python åŸç”Ÿ `logging` æ¨¡å—ä½œä¸ºæ ¸å¿ƒæ—¥å¿—æ¡†æ¶ï¼Œé…åˆè‡ªå®šä¹‰æ‰©å±•å®ç°åŠŸèƒ½ä¸°å¯Œçš„æ—¥å¿—ç³»ç»Ÿï¼š

#### ä¸»è¦ç»„ä»¶
- **Python logging**: æ ¸å¿ƒæ—¥å¿—æ¡†æ¶
- **è‡ªå®šä¹‰æ ¼å¼åŒ–å™¨**: å¸¦é¢œè‰²çš„æ§åˆ¶å°è¾“å‡º
- **JSON å¤„ç†å™¨**: ç»“æ„åŒ–ç ”ç©¶æ—¥å¿—
- **WebSocket æµå¼è¾“å‡º**: å®æ—¶æ—¥å¿—ä¼ è¾“

### 1.2 æ—¥å¿—çº§åˆ«å’Œåˆ†ç±»

#### æ—¥å¿—çº§åˆ«å®šä¹‰
```python
# æ–‡ä»¶: utils/logger.py
TRACE_LOG_LEVEL = 5  # è‡ªå®šä¹‰è·Ÿè¸ªçº§åˆ«
logging.DEBUG        # è°ƒè¯•çº§åˆ«
logging.INFO         # ä¿¡æ¯çº§åˆ«ï¼ˆé»˜è®¤ï¼‰
logging.WARNING      # è­¦å‘Šçº§åˆ«
logging.ERROR        # é”™è¯¯çº§åˆ«
```

#### æ—¥å¿—åˆ†ç±»
```python
# ä¸»è¦æ—¥å¿—è®°å½•å™¨
logger = logging.getLogger('research')      # ç ”ç©¶æ“ä½œæ—¥å¿—
scraper_logger = logging.getLogger('scraper')  # æŠ“å–æ“ä½œæ—¥å¿—
module_logger = logging.getLogger(__name__)  # æ¨¡å—ç‰¹å®šæ—¥å¿—
```

### 1.3 æ—¥å¿—æ ¼å¼åŒ–

#### æ§åˆ¶å°æ ¼å¼åŒ–ï¼ˆå¸¦é¢œè‰²ï¼‰
```python
# æ–‡ä»¶: utils/logger.py
formatter = DefaultFormatter(
    "%(levelprefix)s [%(asctime)s] %(message)s",
    datefmt="%H:%M:%S"
)

# çº§åˆ«é¢œè‰²å®šä¹‰
level_name_colors = {
    logging.DEBUG: lambda level_name: click.style(str(level_name), fg="cyan"),
    logging.INFO: lambda level_name: click.style(str(level_name), fg="green"),
    logging.WARNING: lambda level_name: click.style(str(level_name), fg="yellow"),
    logging.ERROR: lambda level_name: click.style(str(level_name), fg="red"),
}
```

#### JSON ç»“æ„åŒ–æ—¥å¿—
```python
# æ–‡ä»¶: utils/logging_config.py
class JsonLogFormatter(logging.Formatter):
    """JSON æ ¼å¼åŒ–å™¨ï¼Œç”¨äºç»“æ„åŒ–æ—¥å¿—"""
    def format(self, record):
        log_entry = {
            "timestamp": self.formatTime(record),
            "level": record.levelname,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno
        }
        if hasattr(record, 'research_data'):
            log_entry['research_data'] = record.research_data
        return json.dumps(log_entry)
```

### 1.4 æ—¥å¿—è¾“å‡ºç›®æ ‡

#### å¤šç›®æ ‡è¾“å‡º
1. **æ§åˆ¶å°è¾“å‡º**: å®æ—¶å½©è‰²æ—¥å¿—
2. **æ–‡ä»¶æ—¥å¿—**: å¸¦æ—¶é—´æˆ³çš„æ—¥å¿—æ–‡ä»¶
3. **JSON æ—¥å¿—**: ç»“æ„åŒ–ç ”ç©¶äº‹ä»¶è®°å½•
4. **WebSocket æµ**: å®æ—¶ä¼ è¾“åˆ°å‰ç«¯

#### æ—¥å¿—æ–‡ä»¶é…ç½®
```python
# æ–‡ä»¶: utils/logging_config.py
def setup_research_logging(log_dir="logs"):
    """è®¾ç½®ç ”ç©¶æ—¥å¿—ç³»ç»Ÿ"""
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    os.makedirs(log_dir, exist_ok=True)
    
    # æ–‡ä»¶å¤„ç†å™¨
    file_handler = logging.FileHandler(
        f"{log_dir}/research_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
    )
    
    # JSON å¤„ç†å™¨
    json_handler = logging.FileHandler(
        f"{log_dir}/research_events_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    )
    json_handler.setFormatter(JsonLogFormatter())
```

### 1.5 æ€§èƒ½æ—¥å¿—

#### Token å’Œæˆæœ¬è·Ÿè¸ª
```python
# æ–‡ä»¶: actions/utils.py
async def update_cost(
    prompt_tokens: int,
    completion_tokens: int,
    model: str,
    websocket: Any
) -> None:
    """æ›´æ–°æˆæœ¬ä¿¡æ¯å¹¶é€šè¿‡ WebSocket å‘é€"""
    cost = calculate_cost(prompt_tokens, completion_tokens, model)
    total_tokens = prompt_tokens + completion_tokens
    
    await safe_send_json(websocket, {
        "type": "cost",
        "data": {
            "total_tokens": format_token_count(total_tokens),
            "total_cost": f"${cost:.4f}"
        }
    })
```

#### æ‰§è¡Œæ—¶é—´ç›‘æ§
```python
# æ–‡ä»¶: skills/researcher.py
async def conduct_research(self):
    """æ‰§è¡Œç ”ç©¶å¹¶è®°å½•æ€§èƒ½æŒ‡æ ‡"""
    start_time = time.time()
    
    # æ‰§è¡Œç ”ç©¶...
    context = await self._execute_research()
    
    # è®°å½•æ‰§è¡Œæ—¶é—´
    execution_time = time.time() - start_time
    logger.info(f"Research completed in {execution_time:.2f} seconds")
    
    return context
```

### 1.6 è°ƒè¯•æ—¥å¿—åŠŸèƒ½

#### è¯¦ç»†æ¨¡å¼æ§åˆ¶
```python
# æ–‡ä»¶: config/config.py
def set_verbose(self, verbose: bool) -> None:
    """è®¾ç½®è¯¦ç»†çº§åˆ«"""
    self.llm_kwargs["verbose"] = verbose
    if verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    else:
        logging.getLogger().setLevel(logging.INFO)
```

#### è‡ªå®šä¹‰è·Ÿè¸ªçº§åˆ«
```python
# æ–‡ä»¶: utils/logger.py
def add_trace_level():
    """æ·»åŠ è‡ªå®šä¹‰è·Ÿè¸ªçº§åˆ«"""
    logging.addLevelName(TRACE_LOG_LEVEL, "TRACE")
    
    def trace(self, message, *args, **kwargs):
        if self.isEnabledFor(TRACE_LOG_LEVEL):
            self._log(TRACE_LOG_LEVEL, message, args, **kwargs)
    
    logging.Logger.trace = trace
```

## 2. å›è°ƒ/äº‹ä»¶ç³»ç»Ÿ

### 2.1 è¿›åº¦å›è°ƒ

#### äº‹ä»¶ç±»å‹å®šä¹‰
```python
# æ–‡ä»¶: agent.py
async def _log_event(self, event_type: str, **kwargs):
    """å¤„ç†æ—¥å¿—äº‹ä»¶çš„è¾…åŠ©æ–¹æ³•"""
    if self.log_handler:
        match event_type:
            case "tool":
                await self.log_handler.on_tool_start(
                    kwargs.get('tool_name', ''), 
                    **kwargs
                )
            case "action":
                await self.log_handler.on_agent_action(
                    kwargs.get('action', ''), 
                    **kwargs
                )
            case "research":
                await self.log_handler.on_research_step(
                    kwargs.get('step', ''), 
                    kwargs.get('details', {})
                )
```

#### ç ”ç©¶æ­¥éª¤å›è°ƒ
```python
# æ–‡ä»¶: skills/researcher.py
async def _process_research_step(self, step_name: str, data: dict):
    """å¤„ç†ç ”ç©¶æ­¥éª¤å¹¶è§¦å‘å›è°ƒ"""
    # è®°å½•æ­¥éª¤å¼€å§‹
    await self._log_event("research", step=step_name, status="started")
    
    # æ‰§è¡Œæ­¥éª¤...
    result = await self._execute_step(step_name, data)
    
    # è®°å½•æ­¥éª¤å®Œæˆ
    await self._log_event("research", step=step_name, status="completed", result=result)
    
    return result
```

### 2.2 æˆæœ¬è·Ÿè¸ªå›è°ƒ

#### æˆæœ¬å›è°ƒåˆ›å»º
```python
# æ–‡ä»¶: actions/utils.py
def create_cost_callback(websocket: Any) -> Callable:
    """åˆ›å»ºæˆæœ¬è·Ÿè¸ªå›è°ƒå‡½æ•°"""
    async def cost_callback(
        prompt_tokens: int,
        completion_tokens: int,
        model: str
    ) -> None:
        await update_cost(prompt_tokens, completion_tokens, model, websocket)
    return cost_callback
```

#### æˆæœ¬è®¡ç®—å’Œç´¯ç§¯
```python
# æ–‡ä»¶: agent.py
def add_costs(self, cost: float) -> None:
    """æ·»åŠ ç ”ç©¶æˆæœ¬"""
    self.total_costs += cost
    logger.info(f"Accumulated costs: ${self.total_costs:.4f}")

def get_costs(self) -> float:
    """è·å–æ€»æˆæœ¬"""
    return self.total_costs
```

### 2.3 WebSocket å®æ—¶å›è°ƒ

#### WebSocket ç®¡ç†å™¨
```python
# æ–‡ä»¶: backend/server/websocket_manager.py
class WebSocketManager:
    async def start_streaming(self, task, report_type, report_source, 
                            source_urls, document_urls, tone, websocket, 
                            headers=None, query_domains=[], mcp_enabled=False):
        """å¼€å§‹æµå¼è¾“å‡º"""
        try:
            # å‘é€å¼€å§‹æ¶ˆæ¯
            await websocket.send_json({
                "type": "start",
                "data": {"task": task}
            })
            
            # åˆ›å»ºå¸¦å›è°ƒçš„ç ”ç©¶å™¨
            researcher = GPTResearcher(
                query=task,
                report_type=report_type,
                report_source=report_source,
                tone=tone,
                websocket=websocket,
                headers=headers,
                query_domains=query_domains
            )
            
            # æ‰§è¡Œç ”ç©¶ï¼ˆä¼šè§¦å‘å®æ—¶å›è°ƒï¼‰
            await researcher.conduct_research()
            report = await researcher.write_report()
            
            # å‘é€å®Œæˆæ¶ˆæ¯
            await websocket.send_json({
                "type": "report",
                "data": {"report": report}
            })
            
        except WebSocketDisconnect:
            logger.info("WebSocket disconnected")
        except Exception as e:
            await websocket.send_json({
                "type": "error",
                "data": {"message": str(e)}
            })
```

#### å®‰å…¨çš„ JSON å‘é€
```python
# æ–‡ä»¶: backend/server/websocket_manager.py
async def safe_send_json(websocket, data):
    """å®‰å…¨å‘é€ JSON æ•°æ®"""
    if websocket and not websocket.client_state.disconnected:
        try:
            await websocket.send_json(data)
        except Exception as e:
            logger.error(f"Error sending WebSocket message: {e}")
```

### 2.4 äº‹ä»¶é©±åŠ¨æ¶æ„

#### äº‹ä»¶æµå¤„ç†
```python
# æ–‡ä»¶: mcp/streaming.py
class MCPStreamer:
    async def stream_stage_start(self, stage: str, description: str):
        """æµå¼ä¼ è¾“ç ”ç©¶é˜¶æ®µå¼€å§‹"""
        await self.stream_log(f"ğŸ”§ {stage}: {description}")
    
    async def stream_stage_complete(self, stage: str, result_count: int = None):
        """æµå¼ä¼ è¾“ç ”ç©¶é˜¶æ®µå®Œæˆ"""
        msg = f"âœ… {stage} completed"
        if result_count:
            msg += f": {result_count} results"
        await self.stream_log(msg)
    
    async def stream_progress(self, current: int, total: int, message: str):
        """æµå¼ä¼ è¾“è¿›åº¦æ›´æ–°"""
        percentage = (current / total) * 100
        await self.stream_log(f"ğŸ“Š {message}: {current}/{total} ({percentage:.1f}%)")
```

#### äº‹ä»¶ç›‘å¬å™¨æ¨¡å¼
```python
# æ–‡ä»¶: agent.py
class LogHandler:
    """æ—¥å¿—å¤„ç†å™¨æ¥å£"""
    async def on_tool_start(self, tool_name: str, **kwargs):
        """å·¥å…·å¼€å§‹äº‹ä»¶"""
        pass
    
    async def on_agent_action(self, action: str, **kwargs):
        """ä»£ç†åŠ¨ä½œäº‹ä»¶"""
        pass
    
    async def on_research_step(self, step: str, details: dict):
        """ç ”ç©¶æ­¥éª¤äº‹ä»¶"""
        pass
```

### 2.5 å¯æ‰©å±•çš„ Hook æœºåˆ¶

#### é…ç½® Hook
```python
# æ–‡ä»¶: config/config.py
class Config:
    def __init__(self, config_path: str | None = None):
        # åˆå§‹åŒ– Hook
        self.hooks = {
            'before_research': [],
            'after_research': [],
            'on_error': [],
            'on_cost_update': []
        }
    
    def add_hook(self, event: str, callback: Callable):
        """æ·»åŠ äº‹ä»¶ Hook"""
        if event in self.hooks:
            self.hooks[event].append(callback)
    
    async def trigger_hooks(self, event: str, *args, **kwargs):
        """è§¦å‘äº‹ä»¶ Hook"""
        for callback in self.hooks.get(event, []):
            try:
                if asyncio.iscoroutinefunction(callback):
                    await callback(*args, **kwargs)
                else:
                    callback(*args, **kwargs)
            except Exception as e:
                logger.error(f"Error in hook {event}: {e}")
```

#### LLM å‚æ•° Hook
```python
# æ–‡ä»¶: agent.py
def __init__(self, **kwargs):
    # LLM å‚æ•° Hook
    self.llm_kwargs = kwargs.get('llm_kwargs', {})
    if cfg.verbose:
        self.llm_kwargs["verbose"] = True
```

## 3. é”™è¯¯å¤„ç†å’ŒæŠ¥å‘Š

### 3.1 å¼‚å¸¸æ—¥å¿—

#### ç»“æ„åŒ–å¼‚å¸¸è®°å½•
```python
# æ–‡ä»¶: actions/web_scraping.py
try:
    scraper = Scraper(urls, user_agent, cfg.scraper, worker_pool=worker_pool)
    scraped_data = await scraper.run()
    for item in scraped_data:
        if 'image_urls' in item:
            images.extend(item['image_urls'])
except Exception as e:
    # è®°å½•è¯¦ç»†é”™è¯¯ä¿¡æ¯
    logger.error({
        "error": str(e),
        "type": type(e).__name__,
        "module": "web_scraping",
        "urls_count": len(urls),
        "traceback": traceback.format_exc()
    })
    # å‘é€åˆ° WebSocket
    await websocket.send_json({
        "type": "error",
        "data": {
            "message": f"Scraping error: {e}",
            "details": {
                "urls_processed": len(scraped_data) if 'scraped_data' in locals() else 0
            }
        }
    })
```

### 3.2 é”™è¯¯æ¢å¤æœºåˆ¶

#### WebSocket é”™è¯¯å¤„ç†
```python
# æ–‡ä»¶: backend/server/server_utils.py
async def handle_websocket_communication(websocket, manager):
    """å¤„ç† WebSocket é€šä¿¡å’Œé”™è¯¯æ¢å¤"""
    def run_long_running_task(awaitable: Awaitable) -> asyncio.Task:
        async def safe_run():
            try:
                await awaitable
            except asyncio.CancelledError:
                logger.info("Task cancelled.")
                raise
            except Exception as e:
                logger.error(f"Error running task: {e}\n{traceback.format_exc()}")
                # å‘é€é”™è¯¯æ¶ˆæ¯åˆ°å®¢æˆ·ç«¯
                await websocket.send_json({
                    "type": "logs",
                    "content": "error",
                    "output": f"Error: {e}",
                })
                # è§¦å‘é”™è¯¯ Hook
                await cfg.trigger_hooks('on_error', e, websocket)
        return asyncio.create_task(safe_run())
```

#### é‡è¯•æœºåˆ¶
```python
# æ–‡ä»¶: retrievers/tavily/search.py
async def search_with_retry(self, query: str, max_retries: int = 3):
    """å¸¦é‡è¯•çš„æœç´¢"""
    for attempt in range(max_retries):
        try:
            return await self._search(query)
        except Exception as e:
            if attempt == max_retries - 1:
                raise
            logger.warning(f"Search attempt {attempt + 1} failed, retrying...")
            await asyncio.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
```

### 3.3 ç”¨æˆ·å‹å¥½çš„é”™è¯¯æ¶ˆæ¯

#### åˆ†çº§é”™è¯¯æ˜¾ç¤º
```python
# æ–‡ä»¶: mcp/streaming.py
async def stream_error(self, error_msg: str):
    """æµå¼ä¼ è¾“é”™è¯¯æ¶ˆæ¯"""
    await self.stream_log(f"âŒ {error_msg}")

async def stream_warning(self, warning_msg: str):
    """æµå¼ä¼ è¾“è­¦å‘Šæ¶ˆæ¯"""
    await self.stream_log(f"âš ï¸ {warning_msg}")

async def stream_success(self, success_msg: str):
    """æµå¼ä¼ è¾“æˆåŠŸæ¶ˆæ¯"""
    await self.stream_log(f"âœ… {success_msg}")
```

#### é”™è¯¯ç±»å‹æ˜ å°„
```python
# æ–‡ä»¶: backend/server/server.py
ERROR_MESSAGES = {
    "invalid_api_key": "è¯·æ£€æŸ¥æ‚¨çš„ API å¯†é’¥é…ç½®",
    "rate_limit": "è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åé‡è¯•",
    "network_error": "ç½‘ç»œè¿æ¥é”™è¯¯ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè®¾ç½®",
    "timeout": "è¯·æ±‚è¶…æ—¶ï¼Œè¯·é‡è¯•",
    "unknown": "å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼Œè¯·è”ç³»ç®¡ç†å‘˜"
}

@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    """å…¨å±€å¼‚å¸¸å¤„ç†å™¨"""
    error_type = type(exc).__name__
    user_message = ERROR_MESSAGES.get(error_type, ERROR_MESSAGES["unknown"])
    
    return JSONResponse(
        status_code=500,
        content={
            "error": user_message,
            "type": error_type,
            "timestamp": datetime.now().isoformat()
        }
    )
```

## 4. ç³»ç»Ÿç®¡ç†ç‰¹æ€§

### 4.1 æ—¥å¿—è½®è½¬

#### è‡ªåŠ¨æ—¥å¿—æ¸…ç†
```python
# æ–‡ä»¶: utils/logging_config.py
def setup_log_rotation(log_dir="logs", max_files=10):
    """è®¾ç½®æ—¥å¿—è½®è½¬"""
    # æ¸…ç†æ—§æ—¥å¿—æ–‡ä»¶
    log_files = sorted(glob.glob(f"{log_dir}/*.log"))
    if len(log_files) > max_files:
        for old_file in log_files[:-max_files]:
            os.remove(old_file)
```

### 4.2 æ€§èƒ½ç›‘æ§

#### å…³é”®æŒ‡æ ‡æ”¶é›†
```python
# æ–‡ä»¶: utils/metrics.py
class ResearchMetrics:
    def __init__(self):
        self.metrics = {
            'total_research_time': 0,
            'total_tokens_used': 0,
            'total_cost': 0,
            'queries_count': 0,
            'sources_count': 0,
            'errors_count': 0
        }
    
    def record_research(self, duration: float, tokens: int, cost: float):
        """è®°å½•ç ”ç©¶æŒ‡æ ‡"""
        self.metrics['total_research_time'] += duration
        self.metrics['total_tokens_used'] += tokens
        self.metrics['total_cost'] += cost
        self.metrics['queries_count'] += 1
    
    def get_summary(self):
        """è·å–æŒ‡æ ‡æ‘˜è¦"""
        return {
            **self.metrics,
            'avg_time_per_query': self.metrics['total_research_time'] / max(self.metrics['queries_count'], 1),
            'avg_cost_per_query': self.metrics['total_cost'] / max(self.metrics['queries_count'], 1)
        }
```

### 4.3 å®¡è®¡æ—¥å¿—

#### æ“ä½œå®¡è®¡
```python
# æ–‡ä»¶: utils/audit.py
class AuditLogger:
    def __init__(self):
        self.audit_logger = logging.getLogger('audit')
    
    def log_api_call(self, endpoint: str, method: str, user_id: str = None):
        """è®°å½• API è°ƒç”¨"""
        self.audit_logger.info({
            "event": "api_call",
            "endpoint": endpoint,
            "method": method,
            "user_id": user_id,
            "timestamp": datetime.now().isoformat()
        })
    
    def log_research_request(self, query: str, report_type: str, user_id: str = None):
        """è®°å½•ç ”ç©¶è¯·æ±‚"""
        self.audit_logger.info({
            "event": "research_request",
            "query": query,
            "report_type": report_type,
            "user_id": user_id,
            "timestamp": datetime.now().isoformat()
        })
```

## 5. æœ€ä½³å®è·µ

### 5.1 æ—¥å¿—é…ç½®å»ºè®®
```python
# ç”Ÿäº§ç¯å¢ƒé…ç½®
LOGGING_CONFIG = {
    "version": 1,
    "disable_existing_loggers": False,
    "formatters": {
        "standard": {"format": "%(asctime)s [%(levelname)s] %(name)s: %(message)s"},
        "json": {"()": "utils.logging_config.JsonLogFormatter"}
    },
    "handlers": {
        "console": {
            "class": "logging.StreamHandler",
            "level": "INFO",
            "formatter": "standard",
            "stream": "ext://sys.stdout"
        },
        "file": {
            "class": "logging.handlers.RotatingFileHandler",
            "level": "DEBUG",
            "formatter": "json",
            "filename": "logs/research.log",
            "maxBytes": 10485760,  # 10MB
            "backupCount": 5
        }
    },
    "loggers": {
        "": {"level": "INFO", "handlers": ["console", "file"]},
        "research": {"level": "DEBUG", "propagate": False}
    }
}
```

### 5.2 å›è°ƒä½¿ç”¨æ¨¡å¼
```python
# è‡ªå®šä¹‰å›è°ƒå¤„ç†å™¨
class CustomLogHandler:
    async def on_research_step(self, step: str, details: dict):
        # å‘é€åˆ°ç›‘æ§ç³»ç»Ÿ
        await send_to_monitoring_system(step, details)
        
        # è®°å½•åˆ°æ•°æ®åº“
        await log_to_database(step, details)
        
        # å‘é€é€šçŸ¥
        if step == "completed":
            await send_completion_notification(details)

# ä½¿ç”¨è‡ªå®šä¹‰å¤„ç†å™¨
researcher = GPTResearcher(
    query="AI research",
    log_handler=CustomLogHandler()
)
```

GPT Researcher çš„æ—¥å¿—å’Œå›è°ƒç³»ç»Ÿè®¾è®¡å®Œå–„ï¼Œæä¾›äº†å…¨é¢çš„ç›‘æ§ã€è°ƒè¯•å’Œç”¨æˆ·åé¦ˆèƒ½åŠ›ï¼Œæ”¯æŒå®æ—¶æ›´æ–°ã€ç»“æ„åŒ–æ—¥å¿—è®°å½•å’Œçµæ´»çš„æ‰©å±•æœºåˆ¶ã€‚