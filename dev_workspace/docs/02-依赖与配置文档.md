# GPT Researcher 依赖与配置文档

## 主要第三方依赖库

### 核心框架依赖
- **FastAPI** (>=0.104.1) - Web 框架，用于构建 REST API
- **Uvicorn** (>=0.24.0) - ASGI 服务器，运行 FastAPI 应用
- **WebSockets** (^13.1) - WebSocket 支持，实现实时通信
- **Pydantic** (>=2.5.1) - 数据验证和序列化

### AI/LLM 相关依赖
- **OpenAI** (>=1.3.3) - OpenAI API 客户端
- **LangChain** (^0.3.18) - LLM 应用开发框架
- **LangChain Community** (^0.3.17) - 社区集成
- **LangChain OpenAI** (^0.3.6) - OpenAI 集成
- **LangGraph** (>=0.2.73) - 多代理工作流编排
- **MCP** (>=1.0.0) - Model Context Protocol 支持
- **LangChain MCP Adapters** (>=0.1.0) - MCP 适配器

### 搜索和检索依赖
- **DuckDuckGo Search** (>=4.1.1) - DuckDuckGo 搜索引擎
- **Arxiv** (>=2.0.0) - ArXiv 学术论文检索
- **BeautifulSoup4** (>=4.12.2) - HTML 解析
- **Lxml** (>=4.9.2) - XML/HTML 解析器
- **Requests** (>=2.31.0) - HTTP 请求库

### 文档处理依赖
- **Markdown** (>=3.5.1) - Markdown 处理
- **Python-DocX** (^1.1.0) - Word 文档生成
- **PyMuPDF** (>=1.23.6) - PDF 处理
- **Unstructured** (>=0.13) - 非结构化数据提取
- **HTMLDocX** (^0.0.6) - HTML 到 Word 转换
- **MD2PDF** (>=1.0.1) - Markdown 到 PDF 转换

### 工具库依赖
- **Jinja2** (>=3.1.2) - 模板引擎
- **PyYAML** (>=6.0.1) - YAML 处理
- **Python-Dotenv** (>=1.0.0) - 环境变量管理
- **AIOFiles** (>=23.2.1) - 异步文件操作
- **SQLAlchemy** (>=2.0.28) - ORM 数据库操作
- **Tiktoken** (>=0.7.0) - Token 计算
- **Loguru** (^0.7.2) - 日志库

### 可选依赖 (requirements-txt)
- **Azure Storage Blob** - Azure 存储
- **Playwright** - 浏览器自动化
- **Selenium** - 浏览器自动化
- **Scrapy** - 网络爬虫框架
- **Firecrawl** - 网页抓取服务
- **各种 LangChain 集成**:
  - Anthropic, Cohere, Google, Groq
  - HuggingFace, MistralAI, Together
  - Dashscope, Gigachat, XAI

## 配置文件说明

### 1. 主配置文件

**位置**: `gpt_researcher/config/variables/default.py`

**配置类**: `BaseConfig` 类型，包含以下主要配置项：

#### LLM 配置
```python
# 快速 LLM（用于简单任务）
"FAST_LLM": "openai:gpt-5-mini",
"FAST_TOKEN_LIMIT": 3000,

# 智能 LLM（用于复杂任务）
"SMART_LLM": "openai:gpt-5",
"SMART_TOKEN_LIMIT": 6000,

# 战略 LLM（用于推理任务）
"STRATEGIC_LLM": "openai:o4-mini",
"STRATEGIC_TOKEN_LIMIT": 4000,
```

#### 嵌入模型配置
```python
"EMBEDDING": "openai:text-embedding-3-small",
"SIMILARITY_THRESHOLD": 0.42,
```

#### 检索器配置
```python
"RETRIEVER": "tavily",  # 默认检索器
"MAX_SEARCH_RESULTS_PER_QUERY": 5,
```

#### 研究配置
```python
"TEMPERATURE": 0.4,
"TOTAL_WORDS": 1200,
"MAX_ITERATIONS": 3,
"MAX_SUBTOPICS": 3,
"LANGUAGE": "english",
"REPORT_SOURCE": "web",
"REPORT_FORMAT": "APA",
```

#### 深度研究配置
```python
"DEEP_RESEARCH_BREADTH": 3,
"DEEP_RESEARCH_DEPTH": 2,
"DEEP_RESEARCH_CONCURRENCY": 4,
```

#### MCP 配置
```python
"MCP_SERVERS": [],
"MCP_AUTO_TOOL_SELECTION": True,
"MCP_ALLOWED_ROOT_PATHS": [],
"MCP_STRATEGY": "fast",  # "fast", "deep", "disabled"
"REASONING_EFFORT": "medium",
```

### 2. 环境变量配置

系统支持通过环境变量覆盖配置文件中的设置：

#### LLM 相关环境变量
- `FAST_LLM` - 覆盖默认的快速 LLM
- `SMART_LLM` - 覆盖默认的智能 LLM
- `STRATEGIC_LLM` - 覆盖默认的战略 LLM
- `RETRIEVER` - 设置检索器（支持多个，用逗号分隔）
- `EMBEDDING` - 设置嵌入模型
- `REASONING_EFFORT` - 推理努力程度

#### API 密钥环境变量
- `OPENAI_API_KEY` - OpenAI API 密钥
- `TAVILY_API_KEY` - Tavily 搜索 API 密钥
- `BING_API_KEY` - Bing 搜索 API 密钥
- `GOOGLE_API_KEY` - Google API 密钥
- `GOOGLE_CX` - Google 自定义搜索引擎 ID

#### 已弃用的环境变量（向后兼容）
- `LLM_PROVIDER` - LLM 提供商（使用 FAST_LLM 替代）
- `FAST_LLM_MODEL` - 快速 LLM 模型（使用 FAST_LLM 替代）
- `SMART_LLM_MODEL` - 智能 LLM 模型（使用 SMART_LLM 替代）
- `EMBEDDING_PROVIDER` - 嵌入提供商（使用 EMBEDDING 替代）

### 3. 配置加载机制

**Config 类** (`gpt_researcher/config/config.py`) 提供了灵活的配置管理：

1. **加载顺序**：
   - 首先加载默认配置
   - 如果指定了配置文件路径，则合并配置文件
   - 最后用环境变量覆盖相应配置

2. **配置验证**：
   - 检索器名称验证
   - LLM 模型格式验证
   - 嵌入模型格式验证
   - 文档路径验证

3. **类型转换**：
   - 自动将环境变量字符串转换为正确的类型
   - 支持 bool、int、float、str、list、dict 等类型

### 4. 支持的 LLM 提供商

通过 `_SUPPORTED_PROVIDERS` 定义，包括：
- OpenAI
- Azure OpenAI
- Anthropic
- Google (Gemini)
- Cohere
- Groq
- Ollama
- HuggingFace
- MistralAI
- Together
- 等其他提供商

### 5. 支持的嵌入模型提供商

通过 `_SUPPORTED_PROVIDERS` 定义，包括：
- OpenAI
- Azure OpenAI
- Cohere
- Google
- HuggingFace
- Ollama
- VertexAI
- Bedrock
- 等其他提供商

### 6. 支持的检索器

- Web 搜索：tavily, google, bing, duckduckgo, serper, serpapi
- 学术搜索：arxiv, pubmed, semantic_scholar
- 自定义搜索：searchapi, searx, exa
- MCP：model-context-protocol

## 配置示例

### .env 文件示例
```env
# LLM 配置
OPENAI_API_KEY=your_openai_api_key
FAST_LLM=openai:gpt-4o-mini
SMART_LLM=openai:gpt-4o

# 搜索配置
TAVILY_API_KEY=your_tavily_api_key
RETRIEVER=tavily,duckduckgo

# 嵌入配置
EMBEDDING=openai:text-embedding-3-small

# 研究配置
TEMPERATURE=0.4
TOTAL_WORDS=1500
MAX_ITERATIONS=4

# MCP 配置
MCP_STRATEGY=deep
REASONING_EFFORT=high
```

### 自定义配置文件示例
```json
{
  "SMART_LLM": "anthropic:claude-3-sonnet-20240229",
  "FAST_LLM": "groq:llama3-8b-8192",
  "EMBEDDING": "huggingface:sentence-transformers/all-MiniLM-L6-v2",
  "RETRIEVER": "tavily,arxiv",
  "TOTAL_WORDS": 2000,
  "TEMPERATURE": 0.3,
  "DEEP_RESEARCH_DEPTH": 3
}
```