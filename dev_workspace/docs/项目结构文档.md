# GPT Researcher 项目结构文档

## 完整文件树结构

```
gpt-researcher/
├── gpt_researcher/                    # 核心研究包
│   ├── __init__.py                   # 主入口，导出 GPTResearcher 类
│   ├── agent.py                      # 主要代理类
│   ├── prompts.py                    # 提示词管理
│   │
│   ├── config/                       # 配置管理模块
│   │   ├── __init__.py
│   │   ├── config.py                 # 配置管理类
│   │   └── variables/                 # 配置变量定义
│   │       ├── __init__.py
│   │       ├── base.py               # 基础配置类型
│   │       └── default.py            # 默认配置值
│   │
│   ├── actions/                      # 业务逻辑操作
│   │   ├── __init__.py
│   │   ├── utils.py                  # 工具函数
│   │   ├── query_processing.py       # 查询处理
│   │   ├── retriever.py              # 检索器工厂
│   │   ├── web_scraping.py           # 网页抓取
│   │   ├── report_generation.py      # 报告生成
│   │   ├── markdown_processing.py    # Markdown 处理
│   │   └── agent_creator.py          # 代理创建器
│   │
│   ├── skills/                       # 研究技能模块
│   │   ├── __init__.py
│   │   ├── researcher.py             # 研究协调器
│   │   ├── writer.py                 # 报告生成器
│   │   ├── context_manager.py        # 上下文管理器
│   │   ├── browser.py                # 浏览器管理器
│   │   ├── curator.py                # 源管理器
│   │   └── deep_research.py          # 深度研究技能
│   │
│   ├── llm_provider/                 # LLM 提供商抽象层
│   │   ├── __init__.py
│   │   └── generic/                  # 通用 LLM 提供商
│   │       ├── __init__.py
│   │       └── base.py               # 基础 LLM 提供商类
│   │
│   ├── retrievers/                   # 数据检索器
│   │   ├── __init__.py
│   │   ├── utils.py                  # 检索器工具
│   │   ├── tavily/                   # Tavily 搜索
│   │   ├── google/                   # Google 搜索
│   │   ├── bing/                     # Bing 搜索
│   │   ├── duckduckgo/               # DuckDuckGo 搜索
│   │   ├── searx/                    # Searx 元搜索
│   │   ├── searchapi/                # SearchAPI
│   │   ├── serper/                   # Serper API
│   │   ├── serpapi/                  # SerpAPI
│   │   ├── arxiv/                    # ArXiv 学术搜索
│   │   ├── semantic_scholar/         # Semantic Scholar
│   │   ├── pubmed_central/           # PubMed 医学搜索
│   │   ├── exa/                      # Exa 搜索
│   │   ├── custom/                   # 自定义检索器
│   │   └── mcp/                      # Model Context Protocol
│   │
│   ├── document/                     # 文档处理
│   │   ├── __init__.py
│   │   ├── document_loader.py        # 文档加载器
│   │   ├── online_document_loader.py # 在线文档加载
│   │   ├── langchain_document_loader.py # LangChain 文档加载
│   │   └── azure_document_loader.py  # Azure 文档加载
│   │
│   ├── context/                      # 上下文管理
│   │   ├── __init__.py
│   │   └── compression.py            # 上下文压缩
│   │
│   ├── memory/                       # 记忆系统
│   │   ├── __init__.py
│   │   ├── embeddings.py             # 嵌入模型管理
│   │   └── memory.py                 # 记忆类
│   │
│   ├── vector_store/                 # 向量存储
│   │   ├── __init__.py
│   │   └── vector_store.py           # 向量存储包装器
│   │
│   ├── scraper/                      # 网页抓取器
│   │   ├── __init__.py
│   │   ├── arxiv_scraper.py          # ArXiv 抓取器
│   │   ├── beautifulsoup_scraper.py  # BeautifulSoup 抓取器
│   │   ├── newspaper_scraper.py      # Newspaper 抓取器
│   │   ├── playwright_scraper.py     # Playwright 抓取器
│   │   ├── scrapy_scraper.py         # Scrapy 抓取器
│   │   ├── base_scraper.py           # 基础抓取器
│   │   ├── browser_scraper.py        # 浏览器抓取器
│   │   ├── firecrawl_scraper.py      # Firecrawl 抓取器
│   │   ├── pymupdf_scraper.py        # PyMuPDF 抓取器
│   │   └── web_base_loader_scraper.py # WebBaseLoader 抓取器
│   │
│   ├── mcp/                          # Model Context Protocol
│   │   ├── __init__.py
│   │   ├── client.py                 # MCP 客户端
│   │   ├── research.py               # MCP 研究
│   │   ├── streaming.py              # MCP 流式传输
│   │   ├── tool_selector.py          # MCP 工具选择器
│   │   └── utils.py                  # MCP 工具
│   │
│   └── utils/                        # 工具函数
│       ├── __init__.py
│       ├── llm.py                    # LLM 工具
│       ├── costs.py                  # 成本计算
│       ├── logging.py                # 日志工具
│       ├── logger.py                 # 日志器
│       ├── logging_config.py         # 日志配置
│       ├── multi_agents.py           # 多代理工具
│       └── markdown_utils.py         # Markdown 工具
│
├── backend/                          # 后端服务器
│   ├── __init__.py
│   ├── server/                       # FastAPI 服务器
│   │   ├── __init__.py
│   │   ├── server.py                 # 主服务器
│   │   ├── websocket_manager.py      # WebSocket 管理器
│   │   ├── fast_api_app.py           # FastAPI 应用
│   │   └── server_utils.py          # 服务器工具
│   │
│   ├── chat/                         # 聊天功能
│   │   ├── __init__.py
│   │   └── chat.py                   # 聊天实现
│   │
│   ├── report_type/                  # 报告类型处理
│   │   ├── __init__.py
│   │   ├── report_type_headers.py    # 报告类型头部
│   │   ├── report_type_manager.py    # 报告类型管理器
│   │   ├── research_report.py        # 研究报告
│   │   ├── resource_report.py        # 资源报告
│   │   ├── outline_report.py         # 大纲报告
│   │   └── custom_report.py          # 自定义报告
│   │
│   ├── utils.py                      # 后端工具
│   ├── app.py                        # FastAPI 应用
│   └── config.py                     # 后端配置
│
├── multi_agents/                     # 多代理系统
│   ├── __init__.py
│   ├── main.py                       # 多代理主入口
│   ├── agents/                       # 代理实现
│   │   ├── __init__.py
│   │   ├── chief_editor_agent.py     # 主编辑代理
│   │   ├── research_agent.py         # 研究代理
│   │   ├── writer_agent.py           # 写作代理
│   │   ├── editor_agent.py           # 编辑代理
│   │   ├── publisher_agent.py        # 发布代理
│   │   ├── human_agent.py            # 人类代理
│   │   ├── reviewer_agent.py         # 审核代理
│   │   └── reviser_agent.py          # 修订代理
│   │
│   ├── graphs/                       # 工作流图
│   │   ├── __init__.py
│   │   ├── graph.py                  # 工作流图
│   │   └── state.py                  # 状态管理
│   │
│   ├── langgraph.json                # LangGraph 配置
│   ├── memory/                       # 多代理记忆系统
│   │   ├── __init__.py
│   │   ├── draft_memory.py           # 草稿记忆
│   │   └── research_memory.py        # 研究记忆
│   │
│   └── llm.py                        # 多代理 LLM 配置
│
├── frontend/                         # 前端界面
│   ├── index.html                    # HTML 主界面
│   ├── nextjs/                       # Next.js 前端
│   │   ├── src/
│   │   ├── public/
│   │   └── ...
│   └── static/                       # 静态资源
│       ├── css/
│       ├── js/
│       └── images/
│
├── mcp-server/                       # MCP 服务器
│   ├── __init__.py
│   ├── main.py                       # MCP 服务器主入口
│   └── servers/                      # MCP 服务器实现
│       ├── __init__.py
│       ├── search_server.py          # 搜索服务器
│       └── arxiv_server.py           # ArXiv 服务器
│
├── tests/                            # 测试文件
│   ├── __init__.py
│   ├── test_agent.py
│   ├── test_config.py
│   ├── test_retrievers.py
│   └── ...
│
├── docker-compose.yml                # Docker 编排配置
├── Dockerfile                        # Docker 配置
├── main.py                           # 主程序入口
├── cli.py                            # 命令行接口
├── pyproject.toml                    # 项目配置
├── setup.py                          # 安装配置
├── requirements.txt                   # 依赖列表
└── README.md                         # 项目说明
```

## 核心模块详细结构

### 1. gpt_researcher/ 核心包

#### agent.py - 主要代理类
```
class GPTResearcher:
    ├── __init__(
    │   ├── query: str                                          # 研究查询
    │   ├── report_type: str = ReportType.ResearchReport.value  # 报告类型
    │   ├── report_format: str = "markdown"                     # 报告格式
    │   ├── report_source: str = ReportSource.Web.value        # 报告来源
    │   ├── tone: Tone = Tone.Objective                         # 报告语气
    │   ├── source_urls: list[str] | None = None                # 指定源 URL
    │   ├── document_urls: list[str] | None = None             # 文档 URL
    │   ├── complement_source_urls: bool = False               # 补充源 URL
    │   ├── query_domains: list[str] | None = None              # 查询域名
    │   ├── documents=None                                      # 文档对象
    │   ├── vector_store=None                                   # 向量存储
    │   ├── vector_store_filter=None                            # 向量存储过滤器
    │   ├── config_path=None                                   # 配置文件路径
    │   ├── websocket=None                                      # WebSocket 连接
    │   ├── agent=None                                         # 预定义代理类型
    │   ├── role=None                                          # 预定义代理角色
    │   ├── parent_query: str = ""                             # 父查询
    │   ├── subtopics: list | None = None                       # 子主题列表
    │   ├── visited_urls: set | None = None                   # 已访问 URL
    │   ├── verbose: bool = True                               # 详细输出
    │   ├── context=None                                       # 预加载上下文
    │   ├── headers: dict | None = None                       # 请求头
    │   ├── max_subtopics: int = 5                             # 最大子主题数
    │   ├── log_handler=None                                   # 日志处理器
    │   ├── prompt_family: str | None = None                   # 提示词族
    │   ├── mcp_configs: list[dict] | None = None              # MCP 服务器配置
    │   ├── mcp_max_iterations: int | None = None              # MCP 最大迭代次数
    │   ├── mcp_strategy: str | None = None                    # MCP 执行策略
    │   └── **kwargs                                           # 其他参数
    │   )                                                       # 初始化研究器实例
    │
    ├── conduct_research(self, on_progress=None)              # 执行主要研究流程
    ├── write_report(
    │   ├── existing_headers: list = []                       # 现有标题
    │   ├── relevant_written_contents: list = []               # 相关写作内容
    │   ├── ext_context=None                                   # 外部上下文
    │   └── custom_prompt=""                                   # 自定义提示词
    │   ) -> str                                                # 生成研究报告
    │
    ├── write_report_conclusion(self, report_body: str) -> str # 生成报告结论
    ├── write_introduction(self)                                # 生成报告引言
    ├── quick_search(
    │   ├── self, 
    │   ├── query: str, 
    │   └── query_domains: list[str] = None
    │   ) -> list[Any]                                          # 快速搜索查询
    │
    ├── get_subtopics(self)                                     # 获取研究子主题
    ├── get_draft_section_titles(self, current_subtopic: str)   # 获取草稿章节标题
    ├── get_similar_written_contents_by_draft_section_titles(
    │   ├── self,
    │   ├── current_subtopic: str,
    │   ├── draft_section_titles: list[str],
    │   ├── written_contents: list[dict],
    │   └── max_results: int = 10
    │   ) -> list[str]                                          # 获取相似写作内容
    │
    ├── get_research_images(self, top_k=10) -> list[dict[str, Any]] # 获取研究图片
    ├── add_research_images(self, images: list[dict[str, Any]])   # 添加研究图片
    ├── get_research_sources(self) -> list[dict[str, Any]]       # 获取研究来源
    ├── add_research_sources(self, sources: list[dict[str, Any]]) # 添加研究来源
    ├── add_references(self, report_markdown: str, visited_urls: set) -> str # 添加引用
    ├── extract_headers(self, markdown_text: str) -> list[dict]   # 提取 Markdown 标题
    ├── extract_sections(self, markdown_text: str) -> list[dict]  # 提取 Markdown 章节
    ├── table_of_contents(self, markdown_text: str) -> str        # 生成目录
    ├── get_source_urls(self) -> list                            # 获取源 URL
    ├── get_research_context(self) -> list                        # 获取研究上下文
    ├── get_costs(self) -> float                                  # 获取研究成本
    ├── set_verbose(self, verbose: bool)                          # 设置详细模式
    └── add_costs(self, cost: float) -> None                      # 添加研究成本
    │
    ├── _resolve_mcp_strategy(
    │   ├── self, 
    │   ├── mcp_strategy: str | None, 
    │   └── mcp_max_iterations: int | None
    │   ) -> str                                                   # 解析 MCP 策略
    │
    ├── _process_mcp_configs(self, mcp_configs: list[dict]) -> None # 处理 MCP 配置
    ├── _handle_deep_research(self, on_progress=None)              # 处理深度研究
    └── _log_event(self, event_type: str, **kwargs)                # 内部事件日志
```

#### config/ 配置模块
```
config.py
└── class Config:
    ├── __init__(
    │   ├── self, 
    │   ├── config_path: str | None = None
    │   )                                                       # 初始化配置类
    │
    ├── load_config(
    │   ├── cls, 
    │   ├── config_path: str | None
    │   ) -> Dict[str, Any]                                    # 加载配置文件
    │
    ├── parse_retrievers(self, retriever_str: str) -> List[str]  # 解析检索器配置
    ├── parse_llm(
    │   ├── llm_str: str | None
    │   ) -> tuple[str | None, str | None]                      # 解析 LLM 配置
    │
    ├── parse_embedding(
    │   ├── embedding_str: str | None
    │   ) -> tuple[str | None, str | None]                      # 解析嵌入配置
    │
    ├── parse_reasoning_effort(
    │   ├── reasoning_effort_str: str | None
    │   ) -> str | None                                          # 解析推理努力程度
    │
    ├── convert_env_value(
    │   ├── key: str, 
    │   ├── env_value: str, 
    │   ├── type_hint: Type
    │   ) -> Any                                                # 转换环境变量值
    │
    ├── validate_doc_path(self)                                  # 验证文档路径
    ├── set_verbose(self, verbose: bool) -> None                 # 设置详细模式
    ├── get_mcp_server_config(
    │   ├── self, 
    │   ├── name: str
    │   ) -> dict                                                # 获取 MCP 服务器配置
    │
    └── _handle_deprecated_attributes(self) -> None              # 处理弃用属性

variables/
├── base.py
│   └── class BaseConfig (TypedDict)                             # 基础配置类型定义
│
└── default.py
    └── DEFAULT_CONFIG: BaseConfig                               # 默认配置值
```

#### actions/ 业务逻辑模块
```
utils.py
├── stream_output(
│   ├── output: str, 
│   ├── websocket=None, 
│   ├── streaming=True, 
│   ├── title=None, 
│   ├── _type=None
│   )                                                          # 流式输出
│
├── safe_send_json(
│   ├── websocket, 
│   ├── data: dict
│   )                                                          # 安全发送 JSON
│
├── calculate_cost(
│   ├── prompt_tokens: int, 
│   ├── completion_tokens: int, 
│   ├── model: str
│   )                                                          # 计算成本
│
├── update_cost(
│   ├── prompt_tokens: int, 
│   ├── completion_tokens: int, 
│   ├── model: str, 
│   ├── websocket: Any
│   )                                                          # 更新成本
│
├── create_cost_callback(websocket: Any) -> Callable           # 创建成本回调
├── estimate_llm_cost(
│   ├── input_text: str, 
│   ├── output_text: str, 
│   ├── model: str
│   )                                                          # 估算 LLM 成本
└── format_token_count(token_count: int) -> str               # 格式化 Token 数量

query_processing.py
├── get_search_results(
│   ├── query, 
│   ├── retriever, 
│   ├── headers=None, 
│   ├── max_results=5, 
│   ├── query_domains=None
│   )                                                          # 获取搜索结果
│
├── generate_sub_queries(
│   ├── query: str, 
│   ├── parent_query: str, 
│   ├── report_type: str, 
│   ├── context: List[Dict[str, Any]], 
│   ├── cfg: Config, 
│   ├── **kwargs
│   ) -> List[str]                                             # 生成子查询
│
├── plan_research_outline(
│   ├── query: str, 
│   ├── context: List[Dict[str, Any]], 
│   ├── cfg: Config, 
│   ├── parent_query: str = "", 
│   ├── **kwargs
│   ) -> List[str]                                             # 规划研究大纲
│
└── construct_subtopics(
│   ├── query: str, 
│   ├── context: List[Dict[str, Any]], 
│   ├── cfg: Config, 
│   ├── **kwargs
│   ) -> List[str]                                             # 构建子主题

retriever.py
├── get_retriever(retriever: str)                              # 获取检索器类
├── get_retrievers(headers, cfg)                               # 获取检索器列表
├── get_default_retriever()                                    # 获取默认检索器
└── get_all_retriever_names() -> List[str]                      # 获取所有检索器名称

web_scraping.py
└── scrape_urls(
    ├── urls: list[str], 
    ├── user_agent: str, 
    ├── cfg=None, 
    ├── session=None, 
    ├── worker_pool=10
    ) -> list                                                  # 抓取 URL 内容

report_generation.py
├── generate_report(
    ├── query: str, 
    ├── context, 
    ├── report_type: str, 
    ├── tone: Tone, 
    ├── report_source: str, 
    ├── websocket=None, 
    ├── cfg=None, 
    ├── parent_query: str = "", 
    ├── existing_headers: list = [], 
    ├── relevant_written_contents: list = [], 
    ├── cost_callback: Callable = None, 
    ├── headers=None, 
    ├── **kwargs
    ) -> str                                                   # 生成报告
│
├── generate_draft_section_titles(
    ├── current_subtopic: str, 
    ├── report_type: str, 
    ├── context: List[Dict[str, Any]], 
    ├── cfg: Config, 
    ├── **kwargs
    ) -> list[str]                                             # 生成草稿章节标题
│
├── write_report_introduction(
    ├── query: str, 
    ├── report_type: str, 
    ├── context: List[Dict[str, Any]], 
    ├── cfg: Config, 
    ├── **kwargs
    ) -> str                                                   # 写报告引言
│
├── write_conclusion(
    ├── report_body: str, 
    ├── agent: str, 
    ├── role: str, 
    ├── cfg: Config, 
    ├── **kwargs
    ) -> str                                                   # 写结论
│
└── construct_report(
    ├── query: str, 
    ├── context, 
    ├── report_type: str, 
    ├── tone: Tone, 
    ├── report_source: str, 
    ├── websocket=None, 
    ├── cfg=None, 
    ├── **kwargs
    ) -> str                                                   # 构建报告

markdown_processing.py
├── extract_headers(markdown_text: str) -> list[dict]           # 提取标题
├── extract_sections(markdown_text: str) -> list[dict]          # 提取章节
├── table_of_contents(markdown_text: str) -> str               # 生成目录
├── add_references(
    ├── report_markdown: str, 
    ├── visited_urls: set, 
    ├── cfg: Config
    ) -> str                                                   # 添加引用
└── clean markdown(markdown_text: str) -> str                   # 清理 Markdown

agent_creator.py
├── choose_agent(
    ├── task: str, 
    ├── cfg: Config, 
    ├── agent=None, 
    ├── role=None
    )                                                          # 选择代理
├── extract_json_with_regex(
    ├── text: str, 
    ├── json_type: str = "dict"
    )                                                          # 提取 JSON
└── create_agent(
    ├── task: str, 
    ├── agent_type: str, 
    ├── cfg: Config, 
    ├── role: str = None
    )                                                          # 创建代理
```

#### skills/ 技能模块
```
researcher.py
└── class ResearchConductor:
    ├── __init__(self, researcher)                             # 初始化研究指挥器
    ├── conduct_research(self) -> list                          # 执行研究
    ├── plan_research(
    │   ├── self, 
    │   ├── query, 
    │   ├── query_domains=None
    │   ) -> list                                               # 规划研究
    │
    ├── _get_context_by_urls(
    │   ├── self, 
    │   ├── urls
    │   ) -> list                                               # 通过 URL 获取上下文
    │
    ├── _get_context_by_web_search(
    │   ├── self, 
    │   ├── query, 
    │   ├── scraped_data, 
    │   ├── query_domains
    │   ) -> list                                               # 通过网络搜索获取上下文
    │
    ├── _get_context_by_vectorstore(
    │   ├── self, 
    │   ├── query, 
    │   ├── filter
    │   ) -> list                                               # 通过向量存储获取上下文
    │
    ├── _process_sub_query(
    │   ├── self, 
    │   ├── sub_query, 
    │   ├── scraped_data, 
    │   ├── query_domains
    │   ) -> list                                               # 处理子查询
    │
    ├── _execute_mcp_research(
    │   ├── self, 
    │   ├── query, 
    │   ├── query_domains
    │   ) -> list                                               # 执行 MCP 研究
    │
    └── _combine_context(self, context)                       # 合并上下文

writer.py
└── class ReportGenerator:
    ├── __init__(self, researcher)                             # 初始化报告生成器
    ├── write_report(
    │   ├── self, 
    │   ├── existing_headers: list = [], 
    │   ├── relevant_written_contents: list = [], 
    │   ├── ext_context=None, 
    │   ├── custom_prompt=""
    │   ) -> str                                                # 写报告
    │
    ├── write_report_conclusion(
    │   ├── self, 
    │   ├── report_content: str
    │   ) -> str                                                # 写报告结论
    │
    ├── write_introduction(self) -> str                         # 写引言
    ├── get_subtopics(self) -> list                              # 获取子主题
    ├── get_draft_section_titles(
    │   ├── self, 
    │   ├── current_subtopic: str
    │   ) -> list                                               # 获取草稿章节标题
    │
    └── get_similar_written_contents_by_draft_section_titles(
    │   ├── self, 
    │   ├── current_subtopic: str, 
    │   ├── draft_section_titles: list[str], 
    │   ├── written_contents: list[dict], 
    │   ├── max_results: int = 10
    │   ) -> list[str]                                          # 获取相似写作内容
    │

context_manager.py
└── class ContextManager:
    ├── __init__(self, researcher)                             # 初始化上下文管理器
    ├── get_similar_content_by_query(
    │   ├── self, 
    │   ├── query, 
    │   ├── pages
    │   ) -> str                                                # 通过查询获取相似内容
    │
    ├── get_similar_content_by_query_with_vectorstore(
    │   ├── self, 
    │   ├── query, 
    │   ├── filter
    │   ) -> str                                                # 通过向量存储获取相似内容
    │
    └── get_similar_written_contents_by_draft_section_titles(
    │   ├── self, 
    │   ├── current_subtopic: str, 
    │   ├── draft_section_titles: list[str], 
    │   ├── written_contents: list[dict], 
    │   ├── max_results: int = 10
    │   ) -> list[str]                                          # 获取相似写作内容
    │

browser.py
└── class BrowserManager:
    ├── __init__(self, researcher)                             # 初始化浏览器管理器
    ├── browse_urls(
    │   ├── self, 
    │   ├── urls: list[str]
    │   ) -> list[dict]                                         # 浏览 URL
    │
    └── select_top_images(
    │   ├── self, 
    │   ├── images: list[dict], 
    │   ├── k: int = 2
    │   ) -> list[str]                                          # 选择顶级图片
    │

curator.py
└── class SourceCurator:
    ├── __init__(self, researcher)                             # 初始化源管理器
    └── curate_sources(
    │   ├── self, 
    │   ├── sources: list[dict], 
    │   ├── query: str = ""
    │   ) -> list[dict]                                         # 管理源
    │

deep_research.py
└── class DeepResearchSkill:
    ├── __init__(self, researcher)                             # 初始化深度研究技能
    ├── generate_search_queries(
    │   ├── self, 
    │   ├── query: str, 
    │   ├── num_queries: int = 3
    │   ) -> List[Dict[str, str]]                              # 生成搜索查询
    │
    ├── generate_research_plan(
    │   ├── self, 
    │   ├── query: str, 
    │   ├── num_queries: int = 3
    │   ) -> List[Dict[str, str]]                              # 生成研究计划
    │
    ├── process_research_results(
    │   ├── self, 
    │   ├── query: str, 
    │   ├── research_results: List[Dict]
    │   ) -> List[Dict]                                        # 处理研究结果
    │
    ├── deep_research(
    │   ├── self, 
    │   ├── query: str, 
    │   ├── breadth: int, 
    │   ├── depth: int, 
    │   ├── **kwargs
    │   ) -> List[Dict]                                        # 深度研究
    │
    └── run(
    │   ├── self, 
    │   ├── query: str, 
    │   ├── width: int = 3, 
    │   ├── depth: int = 2, 
    │   ├── concurrency_limit: int = 4
    │   ) -> List[Dict]                                        # 运行深度研究
    │
```

#### llm_provider/ LLM 提供商模块
```
generic/base.py
├── class ChatLogger:
│   ├── __init__(
│   │   ├── self, 
│   │   ├── fname: str
│   │   )                                                       # 初始化聊天日志记录器
│   │
│   └── log_request(
│       ├── self, 
│       ├── messages, 
│       ├── response
│       )                                                       # 记录聊天请求和响应
│
└── class GenericLLMProvider:
    ├── __init__(
    │   ├── self, 
    │   ├── llm, 
    │   ├── chat_log: str | None = None, 
    │   ├── verbose: bool = True
    │   )                                                       # 初始化通用 LLM 提供商
    │
    ├── from_provider(
    │   ├── cls, 
    │   ├── provider: str, 
    │   ├── chat_log: str | None = None, 
    │   ├── verbose: bool = True, 
    │   ├── **kwargs: Any
    │   )                                                       # 从提供商创建实例
    │
    ├── get_chat_response(
    │   ├── self, 
    │   ├── messages, 
    │   ├── stream, 
    │   ├── websocket=None, 
    │   ├── **kwargs
    │   )                                                       # 获取聊天响应
    │
    └── stream_response(
        ├── self, 
        ├── messages, 
        ├── websocket=None, 
        ├── **kwargs
        )                                                       # 流式响应
        │
        ├── _send_output(
        │   ├── self, 
        │   ├── content, 
        │   ├── websocket=None
        │   )                                                   # 内部发送输出
        │
        └── _check_pkg(pkg: str) -> None                         # 检查包是否安装
```

**支持的 LLM 提供商 (21个)**:
- OpenAI, Anthropic, Azure OpenAI, Cohere, Google Vertex AI, Google GenAI
- Fireworks, Ollama, Together, Mistral AI, Hugging Face, Groq, AWS Bedrock
- Dashscope, XAI, DeepSeek, LiteLLM, GigaChat, OpenRouter, VLLM OpenAI, AIMLAPI

**常量定义**:
- `_SUPPORTED_PROVIDERS`: 支持的提供商集合
- `NO_SUPPORT_TEMPERATURE_MODELS`: 不支持温度的模型列表
- `SUPPORT_REASONING_EFFORT_MODELS`: 支持推理努力的模型列表
- `ReasoningEfforts`: 推理努力程度枚举

#### retrievers/ 检索器模块
```
__init__.py
├── VALID_RETRIEVERS                                          # 有效检索器列表
└── get_all_retriever_names() -> List[str]                   # 获取所有检索器名称

utils.py
├── stream_output(
│   ├── log_type, 
│   ├── step, 
│   ├── content, 
│   ├── websocket=None, 
│   ├── with_data=False, 
│   ├── data=None
│   )                                                       # 流式输出
│
└── check_pkg(pkg: str) -> None                             # 检查包是否安装

tavily/tavily_search.py
└── class TavilySearch:
    ├── __init__(
    │   ├── self, 
    │   ├── query, 
    │   ├── headers=None, 
    │   ├── topic="general", 
    │   ├── query_domains=None
    │   )                                                       # 初始化 Tavily 搜索
    │
    ├── get_api_key(self)                                      # 获取 API 密钥
    ├── _search(
    │   ├── self, 
    │   ├── query: str, 
    │   ├── search_depth="basic", 
    │   ├── topic="general", 
    │   ├── days=2, 
    │   ├── max_results=10, 
    │   ├── include_domains=None, 
    │   ├── exclude_domains=None, 
    │   ├── include_answer=False, 
    │   ├── include_raw_content=False, 
    │   ├── include_images=False, 
    │   ├── use_cache=True
    │   ) -> dict                                               # 内部搜索方法
    │
    └── search(self, max_results=10)                           # 执行搜索

google/google.py
└── class GoogleSearch:
    ├── __init__(
    │   ├── self, 
    │   ├── query, 
    │   ├── headers=None, 
    │   ├── query_domains=None
    │   )                                                       # 初始化 Google 搜索
    │
    ├── get_api_key(self)                                      # 获取 API 密钥
    ├── get_cx_key(self)                                       # 获取 CX 密钥
    └── search(self, max_results=7)                           # 执行搜索

bing/bing.py
└── class BingSearch:
    ├── __init__(
    │   ├── self, 
    │   ├── query, 
    │   ├── query_domains=None
    │   )                                                       # 初始化 Bing 搜索
    │
    ├── get_api_key(self)                                      # 获取 API 密钥
    └── search(self, max_results=7)                           # 执行搜索

duckduckgo/duckduckgo.py
└── class Duckduckgo:
    ├── __init__(
    │   ├── self, 
    │   ├── query, 
    │   ├── query_domains=None
    │   )                                                       # 初始化 DuckDuckGo 搜索
    │
    └── search(self, max_results=5)                           # 执行搜索

serper/serper.py
└── class SerperSearch:
    ├── __init__(
    │   ├── self, 
    │   ├── query, 
    │   ├── query_domains=None, 
    │   ├── country=None, 
    │   ├── language=None, 
    │   ├── time_range=None, 
    │   ├── exclude_sites=None
    │   )                                                       # 初始化 Serper 搜索
    │
    ├── _get_exclude_sites_from_env(self)                      # 获取排除站点
    ├── get_api_key(self)                                      # 获取 API 密钥
    └── search(self, max_results=7)                           # 执行搜索

serpapi/serpapi.py
└── class SerpApiSearch:
    ├── __init__(
    │   ├── self, 
    │   ├── query, 
    │   ├── query_domains=None
    │   )                                                       # 初始化 SerpApi 搜索
    │
    ├── get_api_key(self)                                      # 获取 API 密钥
    └── search(self, max_results=7)                           # 执行搜索

exa/exa.py
└── class ExaSearch:
    ├── __init__(
    │   ├── self, 
    │   ├── query, 
    │   ├── query_domains=None
    │   )                                                       # 初始化 Exa 搜索
    │
    ├── _retrieve_api_key(self)                                # 获取 API 密钥
    ├── search(
    │   ├── self, 
    │   ├── max_results=10, 
    │   ├── use_autoprompt=False, 
    │   ├── search_type="neural", 
    │   ├── **filters
    │   )                                                       # 执行搜索
    │
    ├── find_similar(
    │   ├── self, 
    │   ├── url, 
    │   ├── exclude_source_domain=False, 
    │   ├── **filters
    │   )                                                       # 查找相似文档
    │
    └── get_contents(
        ├── self, 
        ├── ids, 
        ├── **options
        )                                                       # 获取内容

arxiv/arxiv.py
└── class ArxivSearch:
    ├── __init__(
    │   ├── self, 
    │   ├── query, 
    │   ├── sort='Relevance', 
    │   ├── query_domains=None
    │   )                                                       # 初始化 ArXiv 搜索
    │
    └── search(self, max_results=5)                           # 执行搜索

semantic_scholar/semantic_scholar.py
└── class SemanticScholarSearch:
    ├── __init__(
    │   ├── self, 
    │   ├── query: str, 
    │   ├── sort: str = "relevance", 
    │   ├── query_domains=None
    │   )                                                       # 初始化 Semantic Scholar 搜索
    │
    └── search(self, max_results: int = 20)                    # 执行搜索

searx/searx.py
└── class SearxSearch:
    ├── __init__(
    │   ├── self, 
    │   ├── query: str, 
    │   ├── query_domains=None
    │   )                                                       # 初始化 Searx 搜索
    │
    ├── get_searxng_url(self) -> str                           # 获取 SearxNG URL
    └── search(self, max_results: int = 10)                   # 执行搜索

searchapi/searchapi.py
└── class SearchApiSearch:
    ├── __init__(
    │   ├── self, 
    │   ├── query, 
    │   ├── query_domains=None
    │   )                                                       # 初始化 SearchAPI 搜索
    │
    ├── get_api_key(self)                                      # 获取 API 密钥
    └── search(self, max_results=7)                           # 执行搜索

pubmed_central/pubmed_central.py
└── class PubMedCentralSearch:
    ├── __init__(
    │   ├── self, 
    │   ├── query, 
    │   ├── query_domains=None
    │   )                                                       # 初始化 PubMed 搜索
    │
    ├── _retrieve_api_key(self)                                # 获取 API 密钥
    ├── search(self, max_results=10)                           # 执行搜索
    ├── fetch(self, ids)                                       # 获取文章内容
    ├── has_body_content(self, xml_content)                    # 检查是否有正文内容
    └── parse_xml(self, xml_content)                           # 解析 XML 内容

custom/custom.py
└── class CustomRetriever:
    ├── __init__(
    │   ├── self, 
    │   ├── query: str, 
    │   ├── query_domains=None
    │   )                                                       # 初始化自定义检索器
    │
    ├── _populate_params(self) -> Dict[str, Any]              # 填充参数
    └── search(self, max_results: int = 5)                    # 执行搜索

mcp/retriever.py
└── class MCPRetriever:
    ├── __init__(
    │   ├── self, 
    │   ├── query: str, 
    │   ├── headers: Optional[Dict[str, str]] = None, 
    │   ├── query_domains: Optional[List[str]] = None, 
    │   ├── websocket=None, 
    │   ├── researcher=None, 
    │   ├── **kwargs
    │   )                                                       # 初始化 MCP 检索器
    │
    ├── _get_mcp_configs(self) -> List[Dict[str, Any]]        # 获取 MCP 配置
    ├── _get_config(self)                                       # 获取配置
    ├── search_async(self, max_results: int = 10)              # 异步搜索
    ├── search(self, max_results: int = 10)                    # 同步搜索
    └── _get_all_tools(self)                                   # 获取所有工具
```

**支持的检索器 (14个)**:
- TavilySearch, GoogleSearch, BingSearch, Duckduckgo, SerperSearch
- SerpApiSearch, ExaSearch, ArxivSearch, SemanticScholarSearch, SearxSearch
- SearchApiSearch, PubMedCentralSearch, CustomRetriever, MCPRetriever

#### memory/ 记忆模块
```
embeddings.py
└── class Memory:
    ├── __init__(
    │   ├── self, 
    │   ├── embedding_provider: str, 
    │   ├── embedding_model: str, 
    │   ├── **kwargs
    │   )                                                       # 初始化记忆类
    │
    └── get_embeddings(self, text)                             # 获取文本嵌入向量

__init__.py
└── exports Memory class                                       # 导出 Memory 类
```

**支持的嵌入提供商 (18个)**:
- OpenAI, Azure OpenAI, Cohere, Google Vertex AI, Google GenAI, Hugging Face
- Ollama, Mistral AI, Llama.cpp, Bedrock, Vertex AI Gemini, Together
- Fireworks, Nomic, Voyage AI, Jina, Silo, Xinference

#### vector_store/ 向量存储模块
```
vector_store.py
└── class VectorStoreWrapper:
    ├── __init__(
    │   ├── self, 
    │   ├── vector_store
    │   )                                                       # 初始化向量存储包装器
    │
    ├── load(
    │   ├── self, 
    │   ├── documents
    │   )                                                       # 加载文档到向量存储
    │
    ├── similarity_search(
    │   ├── self, 
    │   ├── query, 
    │   ├── k=4, 
    │   ├── filter=None
    │   )                                                       # 相似性搜索
    │
    ├── _create_langchain_documents(
    │   ├── self, 
    │   ├── documents
    │   )                                                       # 创建 LangChain 文档
    │
    └── _split_documents(
        ├── self, 
        ├── documents
        )                                                       # 分割文档

__init__.py
└── exports VectorStoreWrapper class                           # 导出 VectorStoreWrapper 类
```

#### backend/memory/ 后端记忆状态管理
```
research.py
└── class ResearchState (TypedDict):                           # 研究状态类型定义
    ├── task: str                                              # 研究任务
    ├── report_type: str                                       # 报告类型
    ├── report_source: str                                     # 报告来源
    ├── tone: str                                              # 报告语气
    ├── query_domains: list[str] | None                        # 查询域名
    ├── headers: dict | None                                   # 请求头
    ├── parent_query: str                                      # 父查询
    ├── subtopics: list | None                                 # 子主题
    ├── visited_urls: set                                      # 已访问 URL
    ├── research_images: list                                  # 研究图片
    ├── research_sources: list                                 # 研究来源
    ├── context: list                                         # 上下文
    ├── agent: str | None                                      # 代理类型
    ├── role: str | None                                       # 代理角色
    ├── report: str | None                                     # 报告内容
    ├── report_markdown: str | None                            # Markdown 报告
    ├── report_conclusion: str | None                          # 报告结论
    ├── report_introduction: str | None                        # 报告引言
    ├── costs: float                                           # 成本
    ├── logs: list                                             # 日志
    ├── websocket: Any | None                                  # WebSocket 连接
    ├── config: Config | None                                  # 配置对象
    └── human_feedback: str | None                             # 人类反馈

draft.py
└── class DraftState (TypedDict):                             # 草稿状态类型定义
    ├── task: str                                              # 任务
    ├── current_subtopic: str                                  # 当前子主题
    ├── draft_section_titles: list[str] | None                # 草稿章节标题
    ├── written_contents: list[dict] | None                    # 写作内容
    ├── current_draft_section_titles: list[str] | None         # 当前草稿章节标题
    ├── current_written_contents: list[dict] | None            # 当前写作内容
    ├── report_type: str                                       # 报告类型
    ├── tone: str                                              # 语气
    ├── websocket: Any | None                                  # WebSocket 连接
    └── config: Config | None                                  # 配置对象
```

#### multi_agents/memory/ 多代理记忆状态管理
```
research.py
└── class ResearchState (TypedDict):                           # 多代理研究状态
    ├── task: str                                              # 研究任务
    ├── report_type: str                                       # 报告类型
    ├── report_source: str                                     # 报告来源
    ├── tone: str                                              # 报告语气
    ├── query_domains: list[str] | None                        # 查询域名
    ├── headers: dict | None                                   # 请求头
    ├── parent_query: str                                      # 父查询
    ├── subtopics: list | None                                 # 子主题
    ├── visited_urls: set                                      # 已访问 URL
    ├── research_images: list                                  # 研究图片
    ├── research_sources: list                                 # 研究来源
    ├── context: list                                         # 上下文
    ├── agent: str | None                                      # 代理类型
    ├── role: str | None                                       # 代理角色
    ├── report: str | None                                     # 报告内容
    ├── report_markdown: str | None                            # Markdown 报告
    ├── report_conclusion: str | None                          # 报告结论
    ├── report_introduction: str | None                        # 报告引言
    ├── costs: float                                           # 成本
    ├── logs: list                                             # 日志
    ├── websocket: Any | None                                  # WebSocket 连接
    ├── config: Config | None                                  # 配置对象
    └── human_feedback: str | None                             # 人类反馈

draft.py
└── class DraftState (TypedDict):                             # 多代理草稿状态
    ├── task: str                                              # 任务
    ├── current_subtopic: str                                  # 当前子主题
    ├── draft_section_titles: list[str] | None                # 草稿章节标题
    ├── written_contents: list[dict] | None                    # 写作内容
    ├── current_draft_section_titles: list[str] | None         # 当前草稿章节标题
    ├── current_written_contents: list[dict] | None            # 当前写作内容
    ├── report_type: str                                       # 报告类型
    ├── tone: str                                              # 语气
    ├── websocket: Any | None                                  # WebSocket 连接
    └── config: Config | None                                  # 配置对象
```

#### backend/ 后端服务器模块
```
chat/chat.py
└── class ChatAgentWithMemory:
    ├── __init__(
    │   ├── self, 
    │   ├── report: str, 
    │   ├── config_path, 
    │   ├── headers, 
    │   ├── vector_store = None
    │   )                                                       # 初始化聊天代理
    │
    ├── create_agent(self)                                      # 创建 React 代理图
    ├── vector_store_tool(
    │   ├── self, 
    │   ├── vector_store
    │   ) -> Tool                                               # 创建向量存储工具
    │
    ├── chat(
    │   ├── self, 
    │   ├── message, 
    │   ├── websocket
    │   )                                                       # 与 React 代理聊天
    │
    ├── get_context(self)                                       # 获取聊天上下文
    └── _process_document(
        ├── self, 
        ├── report
        )                                                       # 分割报告为块

server/websocket_manager.py
└── class WebSocketManager:
    ├── __init__(self)                                          # 初始化 WebSocket 管理器
    ├── connect(
    │   ├── self, 
    │   ├── websocket: WebSocket
    │   )                                                       # 连接 WebSocket
    │
    ├── disconnect(
    │   ├── self, 
    │   ├── websocket: WebSocket
    │   )                                                       # 断开 WebSocket
    │
    ├── start_streaming(
    │   ├── self, 
    │   ├── task, 
    │   ├── report_type, 
    │   ├── report_source, 
    │   ├── source_urls, 
    │   ├── document_urls, 
    │   ├── tone, 
    │   ├── websocket, 
    │   ├── headers=None, 
    │   ├── query_domains=[], 
    │   ├── mcp_enabled=False, 
    │   ├── mcp_strategy="fast", 
    │   ├── mcp_configs=[]
    │   )                                                       # 开始流式输出
    │
    ├── chat(
    │   ├── self, 
    │   ├── message, 
    │   ├── websocket
    │   )                                                       # 聊天功能
    │
    └── start_sender(
        ├── self, 
        ├── websocket: WebSocket
        )                                                       # 启动发送任务

server/server_utils.py
├── class CustomLogsHandler:
│   ├── __init__(
│   │   ├── self, 
│   │   ├── websocket, 
│   │   ├── task: str
│   │   )                                                       # 初始化日志处理器
│   │
│   └── send_json(
│       ├── self, 
│       ├── data: Dict[str, Any]
│       ) -> None                                              # 发送 JSON 数据
│
├── class Researcher:
│   ├── __init__(
│   │   ├── self, 
│   │   ├── query: str, 
│   │   ├── report_type: str = "research_report"
│   │   )                                                       # 初始化研究器
│   │
│   └── research(self) -> dict                                 # 执行研究
│
├── sanitize_filename(filename: str) -> str                    # 清理文件名
├── handle_start_command(
│   ├── websocket, 
│   ├── data: str, 
│   ├── manager
│   )                                                       # 处理开始命令
├── handle_human_feedback(data: str)                           # 处理人类反馈
├── handle_chat(
│   ├── websocket, 
│   ├── data: str, 
│   ├── manager
│   )                                                       # 处理聊天消息
├── generate_report_files(
│   ├── report: str, 
│   ├── filename: str
│   ) -> Dict[str, str]                                      # 生成报告文件
├── send_file_paths(
│   ├── websocket, 
│   ├── file_paths: Dict[str, str]
│   )                                                       # 发送文件路径
├── get_config_dict(...) -> Dict[str, str]                    # 获取配置字典
├── update_environment_variables(
│   ├── config: Dict[str, str]
│   )                                                       # 更新环境变量
├── handle_file_upload(
│   ├── file, 
│   ├── DOC_PATH: str
│   ) -> Dict[str, str]                                      # 处理文件上传
├── handle_file_deletion(
│   ├── filename: str, 
│   ├── DOC_PATH: str
│   ) -> JSONResponse                                        # 处理文件删除
├── execute_multi_agents(manager) -> Any                       # 执行多代理
├── handle_websocket_communication(
│   ├── websocket, 
│   ├── manager
│   )                                                       # 处理 WebSocket 通信
└── extract_command_data(
    ├── json_data: Dict
    ) -> tuple                                                # 提取命令数据

server/app.py
├── class ResearchRequest                                      # 研究请求模型
├── class ConfigRequest                                       # 配置请求模型
├── GET /                                                     # 根端点
├── GET /report/{research_id}                                 # 获取报告
├── POST /report/                                             # 生成报告
├── GET /files/                                               # 列出文件
├── POST /api/multi_agents                                    # 运行多代理
├── POST /upload/                                             # 上传文件
├── DELETE /files/{filename}                                 # 删除文件
└── WebSocket /ws                                             # WebSocket 端点

report_type/basic_report/basic_report.py
└── class BasicReport:
    ├── __init__(
    │   ├── self, 
    │   ├── query: str, 
    │   ├── query_domains: list, 
    │   ├── report_type: str, 
    │   ├── report_source: str, 
    │   ├── source_urls, 
    │   ├── document_urls, 
    │   ├── tone: Any, 
    │   ├── config_path: str, 
    │   ├── websocket: WebSocket, 
    │   ├── headers=None, 
    │   ├── mcp_configs=None, 
    │   ├── mcp_strategy=None
    │   )                                                       # 初始化基础报告
    │
    └── run(self)                                              # 执行基础研究报告生成

report_type/detailed_report/detailed_report.py
└── class DetailedReport:
    ├── __init__(
    │   ├── self, 
    │   ├── query: str, 
    │   ├── report_type: str, 
    │   ├── report_source: str, 
    │   ├── source_urls: List[str] = [], 
    │   ├── document_urls: List[str] = [], 
    │   ├── query_domains: List[str] = [], 
    │   ├── config_path: str = None, 
    │   ├── tone: Any = "", 
    │   ├── websocket: WebSocket = None, 
    │   ├── subtopics: List[Dict] = [], 
    │   ├── headers: Optional[Dict] = None, 
    │   ├── complement_source_urls: bool = False, 
    │   ├── mcp_configs=None, 
    │   ├── mcp_strategy=None
    │   )                                                       # 初始化详细报告
    │
    ├── run(self) -> str                                       # 运行详细研究报告生成
    ├── _initial_research(self) -> None                        # 执行初始研究
    ├── _get_all_subtopics(self) -> List[Dict]                 # 获取所有子主题
    ├── _generate_subtopic_reports(
    │   ├── self, 
    │   ├── subtopics: List[Dict]
    │   ) -> tuple                                             # 生成子主题报告
    │
    ├── _get_subtopic_report(
    │   ├── self, 
    │   ├── subtopic: Dict
    │   ) -> Dict[str, str]                                    # 获取子主题报告
    │
    └── _construct_detailed_report(
        ├── self, 
        ├── introduction: str, 
        ├── report_body: str
        ) -> str                                                # 构建详细报告

report_type/deep_research/main.py
└── class DeepResearch:
    ├── __init__(
    │   ├── self, 
    │   ├── query: str, 
    │   ├── breadth: int = 4, 
    │   ├── depth: int = 2, 
    │   ├── websocket: Optional[WebSocket] = None, 
    │   ├── tone: Tone = Tone.Objective, 
    │   ├── config_path: Optional[str] = None, 
    │   ├── headers: Optional[Dict] = None, 
    │   ├── concurrency_limit: int = 2
    │   )                                                       # 初始化深度研究
    │
    ├── generate_feedback(
    │   ├── self, 
    │   ├── query: str, 
    │   ├── num_questions: int = 3
    │   ) -> List[str]                                         # 生成后续问题
    │
    ├── generate_serp_queries(
    │   ├── self, 
    │   ├── query: str, 
    │   ├── num_queries: int = 3
    │   ) -> List[Dict[str, str]]                              # 生成 SERP 查询
    │
    ├── process_serp_result(
    │   ├── self, 
    │   ├── query: str, 
    │   ├── context: str, 
    │   ├── num_learnings: int = 3
    │   ) -> Dict[str, List[str]]                              # 处理研究结果
    │
    ├── deep_research(
    │   ├── self, 
    │   ├── query: str, 
    │   ├── breadth: int, 
    │   ├── depth: int, 
    │   ├── learnings: List[str] = None, 
    │   ├── citations: Dict[str, str] = None, 
    │   ├── visited_urls: Set[str] = None, 
    │   ├── on_progress = None
    │   ) -> Dict[str, Any]                                     # 深度迭代研究
    │
    └── run(
        ├── self, 
        ├── on_progress=None
        ) -> str                                                # 运行深度研究过程

utils.py
├── write_to_file(
│   ├── filename: str, 
│   ├── text: str
│   ) -> None                                                  # 异步写入文件
├── write_text_to_md(
│   ├── text: str, 
│   ├── filename: str = ""
│   ) -> str                                                   # 写入 Markdown 文件
├── write_md_to_pdf(
│   ├── text: str, 
│   ├── filename: str = ""
│   ) -> str                                                   # 转换 Markdown 为 PDF
└── write_md_to_word(
    ├── text: str, 
    ├── filename: str = ""
    ) -> str                                                   # 转换 Markdown 为 DOCX
```

**主要特性**:
- **WebSocket 通信**: 实时流式传输研究进度和聊天功能
- **多种报告类型**: 基础、详细和深度研究报告
- **文件管理**: 上传、删除和生成多种格式报告（PDF、DOCX、MD）
- **日志记录**: 研究跟踪的综合日志记录和 JSON 格式
- **MCP 集成**: 模型上下文协议支持增强研究能力
- **多代理支持**: 协调多个研究代理
- **内存管理**: 研究和草稿过程的状态管理

#### multi_agents/ 多代理系统模块
```
agents/orchestrator.py
└── class ChiefEditorAgent:
    ├── __init__(
    │   ├── self, 
    │   ├── task: dict, 
    │   ├── websocket=None, 
    │   ├── stream_output=None, 
    │   ├── tone=None, 
    │   ├── headers=None
    │   )                                                       # 初始化主编代理
    │
    ├── init_research_team(self)                                # 初始化研究团队
    ├── run_research_task(
    │   ├── self, 
    │   ├── task_id=None
    │   )                                                       # 运行研究任务
    │
    ├── _generate_task_id(self)                                # 生成任务 ID
    ├── _create_output_directory(self)                         # 创建输出目录
    ├── _initialize_agents(self)                                # 初始化所有代理
    ├── _create_workflow(self, agents)                         # 创建 LangGraph 工作流
    ├── _add_workflow_edges(self, workflow)                     # 添加工作流边和条件逻辑
    └── _log_research_start(self)                              # 记录研究开始

agents/researcher.py
└── class ResearchAgent:
    ├── __init__(
    │   ├── self, 
    │   ├── websocket=None, 
    │   ├── stream_output=None, 
    │   ├── tone=None, 
    │   ├── headers=None
    │   )                                                       # 初始化研究代理
    │
    ├── research(
    │   ├── self, 
    │   ├── query: str, 
    │   ├── research_report: str = "research_report", 
    │   ├── parent_query: str = "", 
    │   ├── verbose=True, 
    │   ├── source="web", 
    │   ├── tone=None, 
    │   ├── headers=None
    │   )                                                       # 执行研究查询
    │
    ├── run_subtopic_research(
    │   ├── self, 
    │   ├── parent_query: str, 
    │   ├── subtopic: str, 
    │   ├── verbose: bool = True, 
    │   ├── source="web", 
    │   ├── headers=None
    │   )                                                       # 运行子主题研究
    │
    ├── run_initial_research(
    │   ├── self, 
    │   ├── research_state: dict
    │   )                                                       # 运行初始研究
    │
    └── run_depth_research(
        ├── self, 
        ├── draft_state: dict
        )                                                       # 运行深度研究

agents/writer.py
└── class WriterAgent:
    ├── __init__(
    │   ├── self, 
    │   ├── websocket=None, 
    │   ├── stream_output=None, 
    │   ├── headers=None
    │   )                                                       # 初始化写作代理
    │
    ├── get_headers(
    │   ├── self, 
    │   ├── research_state: dict
    │   )                                                       # 获取标准报告标题
    │
    ├── write_sections(
    │   ├── self, 
    │   ├── research_state: dict
    │   )                                                       # 写作引言和结论
    │
    ├── revise_headers(
    │   ├── self, 
    │   ├── task: dict, 
    │   ├── headers: dict
    │   )                                                       # 修订标题
    │
    └── run(
        ├── self, 
        ├── research_state: dict
        )                                                       # 执行写作过程

agents/editor.py
└── class EditorAgent:
    ├── __init__(
    │   ├── self, 
    │   ├── websocket=None, 
    │   ├── stream_output=None, 
    │   ├── tone=None, 
    │   ├── headers=None
    │   )                                                       # 初始化编辑代理
    │
    ├── plan_research(
    │   ├── self, 
    │   ├── research_state: Dict[str, any]
    │   ) -> Dict[str, any]                                      # 规划研究大纲
    │
    └── run_parallel_research(
        ├── self, 
        ├── research_state: Dict[str, any]
        ) -> Dict[str, List[str]]                                # 执行并行研究
        │
        ├── _create_planning_prompt(
        │   ├── self, 
        │   ├── initial_research: str, 
        │   ├── include_human_feedback: bool, 
        │   ├── human_feedback: Optional[str], 
        │   ├── max_sections: int
        │   ) -> List[Dict[str, str]]                             # 创建规划提示词
        │
        ├── _format_planning_instructions(
        │   ├── self, 
        │   ├── initial_research: str, 
        │   ├── include_human_feedback: bool, 
        │   ├── human_feedback: Optional[str], 
        │   ├── max_sections: int
        │   ) -> str                                              # 格式化规划指令
        │
        ├── _initialize_agents(self) -> Dict[str, any]           # 初始化代理
        ├── _create_workflow(self) -> StateGraph                  # 创建工作流
        ├── _log_parallel_research(
        │   ├── self, 
        │   ├── queries: List[str]
        │   ) -> None                                             # 记录并行研究
        │
        └── _create_task_input(
            ├── self, 
            ├── research_state: Dict[str, any], 
            ├── query: str, 
            ├── title: str
            ) -> Dict[str, any]                                   # 创建任务输入

agents/publisher.py
└── class PublisherAgent:
    ├── __init__(
    │   ├── self, 
    │   ├── output_dir: str, 
    │   ├── websocket=None, 
    │   ├── stream_output=None, 
    │   ├── headers=None
    │   )                                                       # 初始化发布代理
    │
    ├── publish_research_report(
    │   ├── self, 
    │   ├── research_state: dict, 
    │   ├── publish_formats: dict
    │   )                                                       # 发布研究报告
    │
    ├── generate_layout(
    │   ├── self, 
    │   ├── research_state: dict
    │   )                                                       # 生成 Markdown 布局
    │
    ├── write_report_by_formats(
    │   ├── self, 
    │   ├── layout: str, 
    │   ├── publish_formats: dict
    │   )                                                       # 按格式写入报告
    │
    └── run(
        ├── self, 
        ├── research_state: dict
        )                                                       # 执行发布过程

agents/reviser.py
└── class ReviserAgent:
    ├── __init__(
    │   ├── self, 
    │   ├── websocket=None, 
    │   ├── stream_output=None, 
    │   ├── headers=None
    │   )                                                       # 初始化修订代理
    │
    ├── revise_draft(
    │   ├── self, 
    │   ├── draft_state: dict
    │   )                                                       # 修订草稿
    │
    └── run(
        ├── self, 
        ├── draft_state: dict
        )                                                       # 执行修订过程

agents/reviewer.py
└── class ReviewerAgent:
    ├── __init__(
    │   ├── self, 
    │   ├── websocket=None, 
    │   ├── stream_output=None, 
    │   ├── headers=None
    │   )                                                       # 初始化审核代理
    │
    ├── review_draft(
    │   ├── self, 
    │   ├── draft_state: dict
    │   )                                                       # 审核草稿
    │
    └── run(
        ├── self, 
        ├── draft_state: dict
        )                                                       # 执行审核过程

agents/human.py
└── class HumanAgent:
    ├── __init__(
    │   ├── self, 
    │   ├── websocket=None, 
    │   ├── stream_output=None, 
    │   ├── headers=None
    │   )                                                       # 初始化人类代理
    │
    └── review_plan(
        ├── self, 
        ├── research_state: dict
        )                                                       # 收集人类反馈

agents/utils/views.py
└── print_agent_output(
    ├── output: str, 
    ├── agent: str = "RESEARCHER"
    )                                                       # 打印代理输出

agents/utils/utils.py
└── sanitize_filename(filename: str) -> str                    # 清理文件名

agents/utils/llms.py
└── call_model(
    ├── prompt: list, 
    ├── model: str, 
    ├── response_format: str | None = None
    )                                                       # 调用语言模型

agents/utils/file_formats.py
├── write_to_file(
│   ├── filename: str, 
│   ├── text: str
│   ) -> None                                                  # 异步写入文件
├── write_text_to_md(
│   ├── text: str, 
│   ├── path: str
│   ) -> str                                                   # 写入 Markdown 文件
├── write_md_to_pdf(
│   ├── text: str, 
│   ├── path: str
│   ) -> str                                                   # 转换 Markdown 为 PDF
└── write_md_to_word(
    ├── text: str, 
    ├── path: str
    ) -> str                                                   # 转换 Markdown 为 DOCX

main.py
├── run_research_task(
│   ├── query, 
│   ├── websocket=None, 
│   ├── stream_output=None, 
│   ├── tone=Tone.Objective, 
│   ├── headers=None
│   )                                                       # 运行研究任务
└── main()                                                    # 主入口点

memory/research.py
└── class ResearchState (TypedDict):                           # 多代理研究状态
    ├── task: dict                                              # 任务配置
    ├── initial_research: str                                   # 初始研究
    ├── sections: List[str]                                     # 研究章节
    ├── research_data: List[dict]                               # 研究数据
    ├── human_feedback: str                                     # 人类反馈
    ├── title: str                                              # 标题
    ├── headers: dict                                           # 标题结构
    ├── date: str                                               # 日期
    ├── table_of_contents: str                                  # 目录
    ├── introduction: str                                       # 引言
    ├── conclusion: str                                         # 结论
    ├── sources: List[str]                                      # 来源
    └── report: str                                             # 报告

memory/draft.py
└── class DraftState (TypedDict):                             # 多代理草稿状态
    ├── task: dict                                              # 任务配置
    ├── topic: str                                              # 主题
    ├── draft: dict                                             # 草稿
    ├── review: str                                             # 审核意见
    └── revision_notes: str                                    # 修订说明
```

**工作流架构**:
1. **浏览阶段**: 使用 GPTResearcher 进行初始研究
2. **规划阶段**: 编辑器创建研究大纲
3. **人类反馈**: 可选的人类计划审核
4. **并行研究**: 每个章节的 研究 → 审核 → 修订 循环
5. **写作**: 编译最终报告
6. **发布**: 多格式输出生成

**核心特性**:
- **LangGraph 工作流**: 使用 LangGraph 进行状态管理和工作流编排
- **条件逻辑**: 支持复杂的代理协作和条件执行
- **并行执行**: 多个代理可并行工作
- **人类参与**: 支持人类反馈和审核
- **多格式输出**: 支持 PDF、DOCX、Markdown 等格式

这个项目结构文档提供了 GPT Researcher 项目的完整文件树和每个模块的详细类与方法结构，包括完整的方法签名和参数信息，符合新的文档要求。